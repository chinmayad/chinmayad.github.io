<!DOCTYPE html>
<html>
	<head>
		<title>Chinmaya Devaraj Website</title>
	</head>
	<body>
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr style="padding:0px">
              <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                      <p class="name" style="text-align: center;">
                        Chinmaya Devaraj
                      </p>
                      <p>I am a Ph.D. candidate in Electrical and Computer Engineering at the University of Maryland College Park, advised by Prof. Yiannis
                        Aloimonos and Dr. Cornelia Fermuller. 
                      </p>
                      <p> My broad field of research is Computer vision and Generative AI. I have contributed to pioneering projects in text-image generation, video-text models, and zero-shot action recognition, holding a patent and multiple publications. My research topics include Multimodal language modeling, video representation learning, vision-language models, LLMs, and action recognition. 
                      </p>
                      <p style="text-align:center">
                        <a href="mailto:chinmayd@terpmail.umd.edu">Email</a> &nbsp;/&nbsp;
                        <a href="data/Chinmaya-Resume.pdf">CV</a> &nbsp;/&nbsp;
                        <a href="https://www.linkedin.com/in/chinmayadevaraj">Linkedin</a> &nbsp;/&nbsp;
                        <a href="https://scholar.google.com/citations?user=yOY8fyQAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                        <a href="https://github.com/chinmayad">Github</a>
                      </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="data/profile-picture.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="data/profile-picture.jpeg" class="hoverZoomLink"></a>
                    </td>
                  </tr>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <h2>Research</h2>
                      <p>
                        My research topics include Multimodal language modeling, video representation learning, vision-language models, LLMs, and action recognition. I am seeking full-time roles in the industry to leverage my expertise for transformative advancements in AI and technology.
                      </p>
                    </td>
                  </tr>
               </table>
               <table>
            <tr>
               <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                   <img src='data/paper1.png' width="200">
                </div>
              </td>
                
                <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2406.05075">
                  <span class="papertitle">Diving DeepWith Video-Text Models in Representing Motion</span>
                </a>
                <br>
                <strong>Chinmaya Devaraj</strong>
                <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                <br>
                <em>Accepted ACL Findings 2024</em>
              </td>
            </tr>

             <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                 <div>
                    <img src='data/paper2.jpeg' width="200">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:75%;vertical-align:middle">
                 <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/papers/Devaraj_Incorporating_Visual_Grounding_in_GCN_for_Zero-Shot_Learning_of_Human_CVPRW_2023_paper.pdf">
                   <span class="papertitle">IncorporatingVisualGroundingInGCNForZero-shotLearning Of Human Object Interaction Actions</span>
                 </a>
                 <br>
                 <strong>Chinmaya Devaraj</strong>
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                 <br>
                 <em>CVPRW 2023 Link</em>
               </td>
             </tr>

             <tr>

                <td style="padding:20px;width:25%;vertical-align:middle">
                    <div>
                       <img src='data/paper1.png' width="200">
                    </div>
                  </td>


                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/papers/Devaraj_Incorporating_Visual_Grounding_in_GCN_for_Zero-Shot_Learning_of_Human_CVPRW_2023_paper.pdf">
                      <span class="papertitle">IncorporatingVisualGroundingInGCNForZero-shotLearning Of Human Object Interaction Actions</span>
                    </a>
                    <br>
                    <strong>Chinmaya Devaraj</strong>
                    <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                    <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                    <br>
                    <em>CVPRW 2023 Link</em>
                  </td>
             </tr>


            </table>
      </table>     
	</body>
</html>
	</body>
</html>
