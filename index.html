<!DOCTYPE html>
<html>
	<head>
		<title>Chinmaya Devaraj Website</title>
    
    <style>
      .papertitle {
          font-size: 16px;
         
          color: blue;
      }
      body 
      {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
      }
  </style>
	</head>
	<body>
		<table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr style="padding:0px">
              <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                      <p class="name" style="text-align: center;">
                        <h4 style="font-size:35px; font-weight: normal;">Chinmaya Devaraj</h4>
                       
                      </p>
                      <p>I am a Final year PhD student graduating in Sept 2024 at University of Maryland College Park with a expertise in Computer vision, Generative AI, LLMs, multimodal learning and few-shot learning for actions. 
                      </p>
                      <p style="color:#FF0000">I am open to full-time job opportunities starting Oct 2024.</p>
                      <p style="text-align:left;font-size:18px">
                        <a href="mailto:chinmayd@terpmail.umd.edu">Email</a> &nbsp;/&nbsp;
                        <a href="data/Chinmaya-Resume.pdf">CV</a> &nbsp;/&nbsp;
                        <a href="https://www.linkedin.com/in/chinmayadevaraj">Linkedin</a> &nbsp;/&nbsp;
                        <a href="https://scholar.google.com/citations?user=yOY8fyQAAAAJ&hl=en"> Google Scholar</a> &nbsp;/&nbsp;
                        <a href="https://github.com/chinmayad">Github</a>
                      </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="data/profile-picture.jpeg"><img style="width:200px; height:200px; object-fit: cover; border-radius: 50%;" alt="profile photo" src="data/profile-picture.jpeg" class="hoverZoomLink"></a>
                    </td>
                  </tr>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <h4 style="font-size:25px; font-weight: normal;">Research</h4>
                      <p>
                        My PhD advisors are <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a> and  <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>. My research areas include action recognition in zero-shot setting, action prediction and anticipation in ego-centric setting, LLMs and multimodal vision-language models. 
                      </p>
                      <p>
                      I am excited to share about my most recent research on 'Improving multimodal video-language models to better represent motion in videos'. The existing video-text models performed poorly compared to human performance, when given motion descriptions on the task of text to video retrieval. We proposed a simple yet effective method to finetune the vision encoder of tlarge video language models. This new method performs better than the existing video-language models.  
                      </p>
                    </td>
                  </tr>
               </table>
              

               <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h4 style="font-size:25px; font-weight: normal;">Publications</h4>
                  <p>


               <table  style="width:1000px">
                
               <tr>
               <td style="padding:20px;width:50px;vertical-align:middle">
                <div>
                   <img src='data/paper1.png' width="200">
                </div>
              </td>
                
                <td style="padding:20px;width:50px;vertical-align:middle">

                <a href="https://arxiv.org/pdf/2406.05075">
                  <span class="papertitle">Diving Deep With Video-Text Models in Representing Motion</span>
                </a>
                <br>
                <strong>Chinmaya Devaraj</strong>,
                <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                <br>
                <em>Accepted ACL Findings 2024</em>
              </td>
            </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper2.jpeg' width="200"  height="170">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:500px;vertical-align:middle">
                 <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/papers/Devaraj_Incorporating_Visual_Grounding_in_GCN_for_Zero-Shot_Learning_of_Human_CVPRW_2023_paper.pdf">
                   <span class="papertitle">Incorporating Visual Grounding In GCN For Zero-shot Learning Of Human Object Interaction Actions</span>
                 </a>
                 <br>
                 <strong>Chinmaya Devaraj</strong>,
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                 <br>
                 <em>CVPRW 2023 </em>
               </td>
             </tr>


             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper3.jpeg' width="200">
                 </div>
                </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/abs/2102.00649.pdf">
                   <span class="papertitle">Forecasting action through contact representations from first person video.</span>
                 </a>
                 <br>
                  Eadom Dessalene*,&nbsp
                  <strong>Chinmaya Devaraj*,&nbsp</strong>
                  Michael Maynord*,&nbsp
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 (* indicates equal contribution)
                 <br>
                 <em>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021</em>
               </td>
             </tr>


             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper4.jpeg' width="200" height="100">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/pdf/2006.03201.pdf">
                   <span class="papertitle">Egocentric object manipulation graphs.</span>
                 </a>
                 <br>
                  Eadom Dessalene,&nbsp
                  Michael Maynord,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 <br>
                 <em>arxiv</em>
               </td>
             </tr>

            

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper7.jpeg' width="200" height="100">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://ieeexplore.ieee.org/abstract/document/9054016">
                   <span class="papertitle">From Symbols to Signals : Symbolic Variational Autoencoders</span>
                 </a>
                 <br>
                 <strong>Chinmaya Devaraj,&nbsp</strong>
                 AritraChowdhury,&nbsp
                 ArpitJain, &nbsp
                 JamesR.Kubricht, &nbsp
                 PeterTu, &nbsp
                 AlbertoSantamaria-Pang &nbsp
                 <br>
                 <em>ICASSP 2020</em>
               </td>
            </tr>

            <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper6.jpeg' width="200" height="140">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://www.worldscientific.com/doi/10.1142/S1793351X20400140">
                   <span class="papertitle">Emergent Languages from Pretrained Embeddings Characterize Latent Concepts in Dynamic Imagery.</span>
                 </a>
                 <br>
                  James Kubricht,&nbsp
                  Alberto Santamaria-Pang,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Aritra Chowdhury,&nbsp
                  Peter Tu &nbsp
                 <br>
                 <em>arxiv</em>
               </td>
             </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper9.jpeg' width="200" height="100">
                 </div>
               </td>
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://ieeexplore.ieee.org/document/8942266">
                   <span class="papertitle">Towards semantic action analysis via emergent language. </span>
                 </a>
                 <br>
                  Alberto Santamaria-Pang,&nbsp
                  James R. Kubricht,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Aritra Chowdhury,&nbsp
                  Peter Tu &nbsp
                 <br>
                 <em>IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR) 2019.</em>
               </td>
             </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper8.jpeg' width="200" height="200">
                 </div>
               </td>
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/abs/1807.00456">
                   <span class="papertitle">Evenly Cascaded Convolutional Networks. </span>
                 </a>
                 <br>
                  Chengxi Ye,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Michael Maynord,&nbsp
                  Peter Tu, &nbsp
                  <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                  <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 <br>
                 <em>The 1st International Workshop on Big Visual Dataset Construction, Management and Applications, IEEE Big Data 2018. <strong>Best Student Paper Award.</strong></em>       
               </td>   
             </tr>
            </table>

            <table style="width:100%;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h4 style="font-size:25px; font-weight: normal;">Research Experience</h4>
              </td>
              </tr>
            </table>

            <table style="width:1000px">
              <tr>
                <td style="padding:20px;width:200px;vertical-align:middle">
                 <div>
                    <img src='data/umd.png' width="120" height="100">
                 </div>
               </td>
                 <td style="padding:20px;width:470px;vertical-align:middle">
                 <span class="papertitle">University of Maryland - Aug 2016 - Present</span>
                 </a>
                 <br>
                 <em>Ph.D. Researcher, Advisors: Prof. Yiannis Aloimonos and Dr Cornelia Fermuller, UMD, MD</em></br>
                  <br>
                  Developed framework for zero-shot action recognition and transfer learning of actions across activity datasets using knowledge graphs and vision language models.
                  <br>
                  Developed a framework for representing motion in videos in video-text models.
                  <br>
                  Developed Evenly Cascaded Neural network, an efficient neural network for image classification.
               </td>
             </tr>
             </table> 
             
             <table style="width:100%;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h4 style="font-size:25px; font-weight: normal;">Professional Experience</h4>
              </td>
              </tr>
            </table>

            <table style="width:1000px">
              <tr>
                <td style="padding:20px;width:200px;vertical-align:middle">
                 <div>
                    <img src='data/ge.png' width="150" height="130">
                 </div>
               </td>
                 <td style="padding:20px;width:470px;vertical-align:middle">
                 <span class="papertitle">GE Research, Nisakyuna, NY - June - Aug 2017</span>
                 </a>
                 <br>
                 <em>Research intern, Computer Vision and Machine learning team</em></br>
                  <br>
                  Designed and evaluated text-guided image generation to understand emergent languages in videos and images.
                  <br>
                  Developed symbolic variational autoencoder to reconstruct images from symbols.
                  <br>
                 Developed domain adaption methods using symbolic variational autoencoder.,&nbsp
               </td>
             </tr>
              <tr>
                <td style="padding:20px;width:200px;vertical-align:middle">
                 <div>
                    <img src='data/honda.jpeg' width="150" height="90">
                 </div>
               </td>
              </td>
              <td style="padding:20px;width:470px;vertical-align:middle">
              <span class="papertitle">Honda Research Institute - June - Aug 2016</span>
              </a>
              <br>
              <em>Research intern, Mountain View, CA</em></br>
               <br>
               Designed and evaluated deep neural network to model driver's visual attention and driver behavior information from driving data. &nbsp;
               <br>
      
               Improved computation speed by 10X by designing efficient methods to process driving data
            </td>

               
                 



                </tr>
             </table> 
              </td>
            </tr>
         </table>
      </table>     
	</body>
</html>
