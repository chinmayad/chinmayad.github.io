<!DOCTYPE html>
<html>
	<head>
		<title>Chinmaya Devaraj Website</title>
    <style>
      .papertitle {
          font-size: 18px;
          font-weight: bold;
          color: blue;
      }
  </style>
	</head>
	<body>
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr style="padding:0px">
              <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                      <p class="name" style="text-align: center;">
                        <h1>Chinmaya Devaraj</h1>
                      </p>
                      <p>I am a Ph.D. candidate in Electrical and Computer Engineering at the University of Maryland College Park, advised by Prof. Yiannis
                        Aloimonos and Dr. Cornelia Fermuller. 
                      </p>
                      <p> My broad field of research is Computer vision and Generative AI. I have contributed to pioneering projects in text-image generation, video-text models, and zero-shot action recognition, holding a patent and multiple publications. My research topics include Multimodal language modeling, video representation learning, vision-language models, LLMs, and action recognition. 
                      </p>
                      <p style="text-align:left">
                        <a href="mailto:chinmayd@terpmail.umd.edu">Email</a> &nbsp;/&nbsp;
                        <a href="data/Chinmaya-Resume.pdf">CV</a> &nbsp;/&nbsp;
                        <a href="https://www.linkedin.com/in/chinmayadevaraj">Linkedin</a> &nbsp;/&nbsp;
                        <a href="https://scholar.google.com/citations?user=yOY8fyQAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                        <a href="https://github.com/chinmayad">Github</a>
                      </p>
                    </td>


                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="data/profile-picture.jpeg"><img style="width:300px; height:300px; object-fit: cover; border-radius: 50%;" alt="profile photo" src="data/profile-picture.jpeg" class="hoverZoomLink"></a>
                    </td>
                  </tr>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <h2>Research</h2>
                      <p>
                        My research topics include Multimodal language modeling, video representation learning, vision-language models, LLMs, and action recognition. I am seeking full-time roles in the industry to leverage my expertise for transformative advancements in AI and technology.
                      </p>
                    </td>
                  </tr>
               </table>
               <table  style="width:800px">
            <tr>
               <td style="padding:20px;width:50px;vertical-align:middle">
                <div>
                   <img src='data/paper1.png' width="200">
                </div>
              </td>
                
                <td style="padding:20px;width:50px;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2406.05075">
                  <span class="papertitle">Diving Deep With Video-Text Models in Representing Motion</span>
                </a>
                <br>
                <strong>Chinmaya Devaraj</strong>,
                <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                <br>
                <em>Accepted ACL Findings 2024</em>
              </td>
            </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper2.jpeg' width="200"  height="170">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:500px;vertical-align:middle">
                 <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/papers/Devaraj_Incorporating_Visual_Grounding_in_GCN_for_Zero-Shot_Learning_of_Human_CVPRW_2023_paper.pdf">
                   <span class="papertitle">Incorporating Visual Grounding In GCN For Zero-shot Learning Of Human Object Interaction Actions</span>
                 </a>
                 <br>
                 <strong>Chinmaya Devaraj</strong>,
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,  
                 <br>
                 <em>CVPRW 2023 </em>
               </td>
             </tr>


             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper3.jpeg' width="200">
                 </div>
                </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/abs/2102.00649.pdf">
                   <span class="papertitle">Forecasting action through contact representations from first person video.</span>
                 </a>
                 <br>
                  Eadom Dessalene*,&nbsp
                  <strong>Chinmaya Devaraj*,&nbsp</strong>
                  Michael Maynord*,&nbsp
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 (* indicates equal contribution)
                 <br>
                 <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>
               </td>
             </tr>


             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper4.jpeg' width="200" height="100">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/pdf/2006.03201.pdf">
                   <span class="papertitle">Egocentric object manipulation graphs.</span>
                 </a>
                 <br>
                  Eadom Dessalene,&nbsp
                  Michael Maynord,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  
                 <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                 <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 <br>
                 <em>arxiv</em>
               </td>
             </tr>

            

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper7.jpeg' width="200" height="100">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://ieeexplore.ieee.org/abstract/document/9054016">
                   <span class="papertitle">From Symbols to Signals : Symbolic Variational Autoencoders</span>
                 </a>
                 <br>
                 <strong>Chinmaya Devaraj,&nbsp</strong>
                 AritraChowdhury,&nbsp
                 ArpitJain, &nbsp
                 JamesR.Kubricht, &nbsp
                 PeterTu, &nbsp
                 AlbertoSantamaria-Pang &nbsp
                 <br>
                 <em>ICASSP 2020</em>
               </td>
            </tr>

            <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper6.jpeg' width="200" height="140">
                 </div>
               </td>
                 
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://www.worldscientific.com/doi/10.1142/S1793351X20400140">
                   <span class="papertitle">Emergent Languages from Pretrained Embeddings Characterize Latent Concepts in Dynamic Imagery.</span>
                 </a>
                 <br>
                  James Kubricht,&nbsp
                  Alberto Santamaria-Pang,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Aritra Chowdhury,&nbsp
                  Peter Tu &nbsp
                 <br>
                 <em>arxiv</em>
               </td>
             </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper9.jpeg' width="200" height="100">
                 </div>
               </td>
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://ieeexplore.ieee.org/document/8942266">
                   <span class="papertitle">Towards semantic action analysis via emergent language. </span>
                 </a>
                 <br>
                  Alberto Santamaria-Pang,&nbsp
                  James R. Kubricht,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Aritra Chowdhury,&nbsp
                  Peter Tu &nbsp
                 <br>
                 <em>IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR) 2019.</em>
               </td>
             </tr>

             <tr>
                <td style="padding:20px;width:50px;vertical-align:middle">
                 <div>
                    <img src='data/paper8.jpeg' width="200" height="200">
                 </div>
               </td>
                 <td style="padding:20px;width:50px;vertical-align:middle">
                 <a href="https://arxiv.org/abs/1807.00456">
                   <span class="papertitle">Evenly Cascaded Convolutional Networks. </span>
                 </a>
                 <br>
                  Chengxi Ye,&nbsp
                  <strong>Chinmaya Devaraj,&nbsp</strong>
                  Michael Maynord,&nbsp
                  Peter Tu, &nbsp
                  <a href="https://users.umiacs.umd.edu/~fer/">Cornelia Fermuller</a>, 
                  <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>
                 <br>
                 <em>The 1st International Workshop on Big Visual Dataset Construction, Management and Applications, IEEE Big Data 2018. <strong>Best Student Paper Award.</strong></em>
                
               </td>
               
             </tr>
  
            </table>
      </table>     
	</body>
</html>


